{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Quy trình ETL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Extract trích xuất dữ liệu**.\n",
    "      - 1.1 Trích xuất dữ liệu LLM_data từ phần LLM.\n",
    "      - 1.2 Trích xuất dữ liệu raw_data phần raw data.\n",
    "2. **Transform dữ liệu**.\n",
    "      - 2.1 Transform cột article_id từ hai nguồn dữ liệu từ dạng float sang kiểu string.\n",
    "      - 2.2 Transform join article_id từ hai nguồn dữ liệu raw_data và LLM_data thành merged_data.\n",
    "      - 2.3 Transform cột price.\n",
    "          - 2.3.1 Loại bỏ các cột giá Thỏa Thuận và transform cột giá.\n",
    "      - 2.4 Transform cột area.\n",
    "          - 2.4.1 Thêm miền chặn dưới của cột area.\n",
    "      - 2.5 Thêm cột area_per_m2\n",
    "      - 2.6 Transform cột date_posted từ dạng object sang kiểu datetime64\n",
    "      - 2.7 Transform cột location sang tọa độ\n",
    "\n",
    "3. **Load Dữ liệu vào file merged data.csv**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Trích xuất dữ liệu**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Trích xuất dữ liệu từ file raw_data_2_from_post.csv**\n",
    "File raw_data_2_post là file chứa dữ liệu sau khi đã crawl data từ trang web batdongsan.com.vn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "raw_data_from_post = pd.read_csv('https://raw.githubusercontent.com/KhiemDangLe/Final-Project/main/DataFolder/2_raw_data_from_post.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Trích xuất dữ liệu từ file raw_data_3_from_LLM.csv**\n",
    "File raw_data_3_from_LLM.csv là file chứa dữ liệu về các thuộc tính của bài đăng được trích xuất từ mô tả của bài đăng nhờ mô hình LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_extracted_by_LLM = pd.read_csv('https://raw.githubusercontent.com/KhiemDangLe/Final-Project/main/DataFolder/3_raw_data_extracted_by_LLM.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Transform dữ liệu**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**raw_data_from_post**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(raw_data_from_post['article_id'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# sử dụng format_float_positional\n",
    "for i in range(len(raw_data_from_post['article_id'])):\n",
    "    raw_data_from_post.loc[i, 'article_id'] = np.format_float_positional(raw_data_from_post.loc[i, 'article_id'], trim='-')\n",
    "raw_data_from_post['article_id'] = raw_data_from_post['article_id'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**raw_data_extracted_by_LLM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(raw_data_extracted_by_LLM['article_id'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(raw_data_extracted_by_LLM['article_id'])):\n",
    "    raw_data_extracted_by_LLM.loc[i, 'article_id'] = np.format_float_positional(raw_data_extracted_by_LLM.loc[i, 'article_id'], trim='-')\n",
    "raw_data_extracted_by_LLM['article_id'] = raw_data_extracted_by_LLM['article_id'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Join dữ liệu từ hai nguồn raw_data_from_post và raw_data_extracted_by_LLM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = raw_data_from_post.merge(raw_data_extracted_by_LLM, on='article_id', how='inner')\n",
    "merged_data.drop_duplicates(subset='article_id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Chuyển đổi cột price**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# loại bỏ dữ liệu các cột có tên là thỏa thuận\n",
    "merged_data.drop(index=merged_data[merged_data['price'] == 'Thỏa thuận'].index, inplace=True)\n",
    "\n",
    "def tach_so_va_don_vi(chuoi):\n",
    "    # Handle non-string values by converting to string\n",
    "    if not isinstance(chuoi, str):\n",
    "        chuoi = str(chuoi)\n",
    "\n",
    "    # Biểu thức chính quy để tìm các phần số và đơn vị\n",
    "    pattern = r'([\\d.]+)\\s*(\\D*)'\n",
    "    \n",
    "    # Tìm tất cả các cặp số và đơn vị trong chuỗi\n",
    "    matches = re.findall(pattern, chuoi)\n",
    "    if matches:\n",
    "        return matches[0]  # Trả về cặp số và đơn vị đầu tiên (nếu có)\n",
    "    else:\n",
    "        return None, None  # Trả về None nếu không tìm thấy\n",
    "\n",
    "# Extract number and unit before dropping 'price' column\n",
    "merged_data[['so', 'don_vi']] = merged_data['price'].apply(tach_so_va_don_vi).apply(pd.Series)\n",
    "merged_data.drop(columns=['price'], inplace=True)\n",
    "\n",
    "merged_data['don_vi'].unique()\n",
    "merged_data['don_vi'].str.strip()\n",
    "merged_data['so'] = merged_data['so'].astype(float)\n",
    "merged_data.info()\n",
    "\n",
    "def convert_value(row):\n",
    "    # Chuyển đổi số thành chuỗi để kiểm tra số chữ số trước dấu thập phân\n",
    "    so_str = str(row['so'])\n",
    "\n",
    "    # Tách phần nguyên và phần thập phân của số\n",
    "    if '.' in so_str:                  # t\n",
    "        integer_part = so_str.split('.')[0]\n",
    "    else:\n",
    "        integer_part = so_str\n",
    "\n",
    "    # Kiểm tra số chữ số của phần nguyên\n",
    "    if len(integer_part) < 5:\n",
    "        if row['don_vi'] == 'tỷ':\n",
    "            return row['so'] * 1000000000\n",
    "        elif row['don_vi'] == 'triệu':\n",
    "            return row['so'] * 1000000\n",
    "        elif row['don_vi'] == 'nghìn':\n",
    "            return row['so'] * 1000\n",
    "        else:\n",
    "            return row['so']\n",
    "    else:\n",
    "        return row['so']\n",
    "\n",
    "\n",
    "# Áp dụng hàm chuyển đổi cho từng hàng của DataFrame\n",
    "merged_data['so'] = merged_data.apply(convert_value, axis=1)\n",
    "merged_data.drop(columns=['don_vi'], inplace=True)\n",
    "merged_data.rename(columns={'so': 'price'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Chuyển đổi cột date_posted từ dạng object sang dạng datetime**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data['date_posted'] = pd.to_datetime(merged_data['date_posted'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Thêm cột price_per_m2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data['price_per_m2'] = merged_data['price'] / merged_data['area']\n",
    "merged_data['price_per_m2'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform cột location sang tọa độ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import time\n",
    "\n",
    "def get_long_lat(location,api_key):\n",
    "    url = f\"https://geocode.maps.co/search?q={location}&api_key={api_key}\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        data = json.loads(response.text)\n",
    "\n",
    "        if data:\n",
    "            longitude = float(data[0][\"lon\"])\n",
    "            latitude = float(data[0][\"lat\"])\n",
    "            print(f\"complete {location}\")\n",
    "            return longitude, latitude\n",
    "        else:\n",
    "            return None, None\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def get_long_df(df, start, end,df_2,api):\n",
    "    for i in range(start, end):\n",
    "      if not pd.isna(df['street_name'][i]):\n",
    "        location = df['street_name'][i] + \" \" + df['district'][i] + \" Thành Phố Hồ Chí Minh\"\n",
    "        longitude, latitude = get_long_lat(location,api)\n",
    "        df_2.at[i, 'longitude'] = longitude\n",
    "        df_2.at[i, 'latitude'] = latitude\n",
    "        df_2.at[i,'article_id']= df['article_id'][i]\n",
    "        time.sleep(1.2)\n",
    "      else :\n",
    "        print(\"11111\")\n",
    "        df_2.at[i, 'longitude'] = None\n",
    "        df_2.at[i, 'latitude'] = None\n",
    "        df_2.at[i,'article_id']= df['article_id'][i]\n",
    "# prompt: đổi kiểu df['street_name'] từ object sang string với cột nào NaN thì để là rỗng\n",
    "\n",
    "df['street_name'] = df['street_name'].astype(str).fillna(\"\")\n",
    "\n",
    "df_2= pd.DataFrame()\n",
    "get_long_df(df,0,len(df),df_2,'API_KEY')\n",
    "# prompt: lưu df vào một file csv có tên là merged_data_with_long_lat.csv\n",
    "\n",
    "df_2.to_csv('/content/drive/MyDrive/Data/merged_data_with_long_lat_0_5000.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load dữ liệu vào file raw_data_4_merged.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
